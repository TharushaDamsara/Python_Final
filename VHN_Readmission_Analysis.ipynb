{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategic Patient Risk Stratification & Readmission Predictive Modeling\n",
    "## Vitality Health Network (VHN)\n",
    "\n",
    "**Course:** ITS 2122: Python for Data Science & AI (Semester 3 – 2025)  \n",
    "**Dataset:** Diabetes 130-US Hospitals (1999–2008)  \n",
    "**Objective:** Analyze historical hospital data to identify drivers of 30-day readmissions and build a risk stratification system\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Phase 1: Data Ingestion & Clinical Sanitation](#phase1)\n",
    "2. [Phase 2: Data Enrichment via Web Scraping](#phase2)\n",
    "3. [Phase 3: Exploratory Data Analysis](#phase3)\n",
    "4. [Phase 4: Feature Engineering - Vitality Complexity Index](#phase4)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from utils import (\n",
    "    calculate_vci_score,\n",
    "    categorize_vci_risk,\n",
    "    scrape_icd9_description,\n",
    "    audit_data_quality,\n",
    "    print_audit_summary,\n",
    "    plot_readmission_by_category,\n",
    "    plot_readmission_rate_by_category,\n",
    "    create_correlation_heatmap\n",
    ")\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='phase1'></a>\n",
    "# Phase 1: Data Ingestion & Clinical Sanitation\n",
    "\n",
    "In this phase, we perform professional healthcare data cleaning:\n",
    "- Load and audit the dataset\n",
    "- Handle missing values and data quality issues\n",
    "- Remove deceased patients\n",
    "- Convert data types appropriately\n",
    "- Remove duplicates\n",
    "- Document all cleaning decisions with clinical rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load main dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata_files/diabetic_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows × \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load ID mappings\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load main dataset\n",
    "df = pd.read_csv('data_files/diabetic_data.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# Load ID mappings\n",
    "id_mapping = pd.read_csv('data_files/IDs_mapping.csv')\n",
    "print(f\"\\nID mapping loaded: {id_mapping.shape[0]} mappings\")\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Initial Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STATISTICAL SUMMARY - NUMERICAL FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for '?' values (common placeholder in healthcare data)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CHECKING FOR '?' PLACEHOLDER VALUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "question_mark_counts = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        count = (df[col] == '?').sum()\n",
    "        if count > 0:\n",
    "            question_mark_counts[col] = count\n",
    "\n",
    "if question_mark_counts:\n",
    "    qm_df = pd.DataFrame.from_dict(question_mark_counts, orient='index', columns=['Count'])\n",
    "    qm_df['Percentage'] = (qm_df['Count'] / len(df) * 100).round(2)\n",
    "    qm_df = qm_df.sort_values('Count', ascending=False)\n",
    "    print(qm_df)\n",
    "else:\n",
    "    print(\"No '?' values found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Convert '?' to NaN\n",
    "\n",
    "**Clinical Rationale:** The '?' symbol is used as a placeholder for missing data in many healthcare datasets. Converting these to NaN allows proper handling with pandas missing data methods and prevents these values from being treated as valid categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "print(\"✓ Converted all '?' values to NaN\")\n",
    "\n",
    "# Verify conversion\n",
    "print(f\"\\nTotal NaN values in dataset: {df.isna().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Comprehensive Data Quality Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform audit using utility function\n",
    "audit_results = audit_data_quality(df)\n",
    "print_audit_summary(audit_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Handle High Missingness Columns\n",
    "\n",
    "**Clinical Rationale:** Columns with >90% missing data provide minimal analytical value and can introduce bias. Common examples in healthcare data:\n",
    "- **weight**: Often not recorded consistently across facilities\n",
    "- **payer_code**: May not be captured in all systems\n",
    "- **medical_specialty**: Frequently missing in administrative data\n",
    "\n",
    "We document these as **data quality limitations** rather than attempting imputation, which would be clinically inappropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with >90% missingness\n",
    "high_missing_threshold = 0.90\n",
    "missing_pct = df.isna().sum() / len(df)\n",
    "high_missing_cols = missing_pct[missing_pct > high_missing_threshold].index.tolist()\n",
    "\n",
    "print(f\"Columns with >{high_missing_threshold*100}% missing data:\")\n",
    "for col in high_missing_cols:\n",
    "    pct = missing_pct[col] * 100\n",
    "    print(f\"  • {col}: {pct:.2f}% missing\")\n",
    "\n",
    "# Drop these columns\n",
    "if high_missing_cols:\n",
    "    df.drop(columns=high_missing_cols, inplace=True)\n",
    "    print(f\"\\n✓ Dropped {len(high_missing_cols)} columns with extreme missingness\")\n",
    "    print(f\"New dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "else:\n",
    "    print(\"\\nNo columns exceed the 90% missingness threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Remove Deceased Patients\n",
    "\n",
    "**Clinical Rationale:** Patients who expired (died) during hospitalization cannot be readmitted and should be excluded from readmission analysis. Including them would:\n",
    "1. Artificially inflate the \"no readmission\" group\n",
    "2. Skew risk models toward end-of-life care patterns\n",
    "3. Violate the clinical definition of readmission risk\n",
    "\n",
    "We use the discharge_disposition_id mapping to identify deceased patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display discharge disposition mappings\n",
    "print(\"Discharge Disposition ID Mappings:\")\n",
    "print(id_mapping[id_mapping['Table'] == 'discharge_disposition_id'])\n",
    "\n",
    "# Identify deceased patient codes\n",
    "# Typically codes 11, 13, 14, 19, 20, 21 indicate expired/hospice/deceased\n",
    "deceased_codes = [11, 13, 14, 19, 20, 21]\n",
    "\n",
    "print(f\"\\nDeceased/Expired discharge codes: {deceased_codes}\")\n",
    "print(f\"Patients before removal: {len(df):,}\")\n",
    "\n",
    "# Count deceased patients\n",
    "deceased_count = df[df['discharge_disposition_id'].isin(deceased_codes)].shape[0]\n",
    "print(f\"Deceased patients identified: {deceased_count:,} ({deceased_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Remove deceased patients\n",
    "df = df[~df['discharge_disposition_id'].isin(deceased_codes)].copy()\n",
    "print(f\"Patients after removal: {len(df):,}\")\n",
    "print(f\"\\n✓ Removed {deceased_count:,} deceased patients from analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Convert to Appropriate Data Types\n",
    "\n",
    "**Clinical Rationale:** Proper data typing improves:\n",
    "- Memory efficiency\n",
    "- Analysis accuracy\n",
    "- Categorical analysis capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [\n",
    "    'race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id',\n",
    "    'admission_source_id', 'max_glu_serum', 'A1Cresult',\n",
    "    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
    "    'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone',\n",
    "    'change', 'diabetesMed', 'readmitted'\n",
    "]\n",
    "\n",
    "# Convert to category dtype\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "print(\"✓ Converted categorical columns to 'category' dtype\")\n",
    "print(f\"\\nMemory usage after conversion: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Remove Duplicate Records\n",
    "\n",
    "**Clinical Rationale:** Duplicate records can occur due to:\n",
    "- Data entry errors\n",
    "- System integration issues\n",
    "- Multiple submissions\n",
    "\n",
    "Duplicates must be removed to ensure accurate statistical analysis and prevent bias in predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicate_count:,}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"✓ Removed {duplicate_count:,} duplicate rows\")\n",
    "else:\n",
    "    print(\"✓ No duplicate rows found\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Phase 1 Summary\n",
    "\n",
    "**Data Cleaning Decisions Summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1: DATA SANITATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCleaning Actions Performed:\")\n",
    "print(\"  1. ✓ Converted '?' placeholders to NaN\")\n",
    "print(f\"  2. ✓ Dropped {len(high_missing_cols) if high_missing_cols else 0} columns with >90% missingness\")\n",
    "print(f\"  3. ✓ Removed {deceased_count:,} deceased patients\")\n",
    "print(\"  4. ✓ Converted categorical columns to appropriate dtype\")\n",
    "print(f\"  5. ✓ Removed {duplicate_count:,} duplicate records\")\n",
    "print(f\"\\nFinal Clean Dataset: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
